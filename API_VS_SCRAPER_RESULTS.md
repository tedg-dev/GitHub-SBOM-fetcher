# API-Based Fetcher vs HTML Scraper - Results Comparison

## Test Repository: tedg-dev/beatBot

| Metric | HTML Scraper | API Fetcher | Improvement |
|--------|-------------|-------------|-------------|
| **Dependencies Found** | 223 | **230** | **+7 (+3.1%)** ‚úÖ |
| **GitHub Repos Mapped** | 167 | **222** | **+55 (+33%)** ‚úÖ |
| **SBOMs Downloaded** | 166 | **220** | **+54 (+33%)** ‚úÖ |
| **SBOMs Failed** | 1 | 2 | +1 |
| **Execution Time** | ~3m 10s | **4m 20s** | +1m 10s ‚ö†Ô∏è |
| **GitHub UI Count** | 229 | 229 | - |
| **Capture Rate** | 97.4% | **100.4%** | **+3.0%** ‚úÖ |

## Key Findings

### 1. More Complete Discovery ‚úÖ
**API Fetcher finds MORE dependencies than GitHub UI shows (230 vs 229)**
- The GitHub SBOM API includes the complete dependency tree
- HTML scraper misses ~7 dependencies due to JavaScript rendering
- API approach captures **everything GitHub knows about**

### 2. Significantly More SBOMs Downloaded ‚úÖ
**220 SBOMs vs 166 SBOMs (+54 more)**
- Better package-to-GitHub mapping via npm/PyPI registry APIs
- Fewer "npm-only" false positives
- More reliable repository URL extraction

### 3. Stable & Maintainable ‚úÖ
**No HTML parsing fragility**
- Uses documented GitHub API (SPDX 2.3 format)
- Package registry APIs are stable and well-documented
- Won't break when GitHub changes UI

### 4. Works for Private Repos ‚úÖ
**Tested on tedg-dev/xplat_fileshare**
- HTML scraper: ‚ùå Failed (404 - web UI disabled)
- API fetcher: ‚úÖ Works perfectly with same credentials

### 5. Slightly Slower ‚ö†Ô∏è
**4m 20s vs 3m 10s (~37% slower)**
- Additional API calls to npm/PyPI registries for mapping
- Rate limiting delays to be respectful
- **Trade-off is worth it for 54 more SBOMs**

## Package-to-Repository Mapping Accuracy

### HTML Scraper Issues:
- Used GitHub href directly from dependency graph page
- Many packages incorrectly mapped or missed
- Example: `abbrev`, `babylon`, etc. marked as "npm-only" despite having GitHub repos

### API Fetcher Solution:
- Queries npm registry API for each package
- Extracts authoritative repository URL from package metadata
- Handles edge cases (scoped packages, monorepos, renamed repos)
- **Result: 222/230 packages mapped (96.5%)**

## Packages Without GitHub Repos (8 total)

Both methods correctly identify these packages have no public GitHub repos:

1. `@ffmpeg-installer/darwin-x64` - Binary distribution
2. `@ffmpeg-installer/win32-ia32` - Binary distribution
3. `@ffmpeg-installer/linux-x64` - Binary distribution
4. `@ffmpeg-installer/linux-ia32` - Binary distribution
5. `@ffmpeg-installer/win32-x64` - Binary distribution
6. `boolbase` - Simple utility, no repo
7. `eyes` - Old package, repo gone
8. `com.github.tedg-dev/beatBot` - Root package (not a dependency)

These are legitimately unmappable - no false positives.

## Detailed Improvements

### Dependencies Now Found (7 additional):
The API fetcher discovered dependencies that HTML scraper missed due to:
- JavaScript-rendered content
- Dynamic loading
- Hidden/collapsed sections
- Pagination edge cases

### SBOMs Now Downloaded (54 additional):
Examples of packages now correctly mapped and downloaded:
- All `isaacs/*` packages that moved to `npm/*` org
- Packages with non-obvious GitHub URLs
- Scoped packages (`@types/*`, `@babel/*`, etc.)
- Packages with complex repository structures

## Execution Performance

### HTML Scraper:
```
Step 1: Scrape HTML pages (12 pages) - ~30s
Step 2: Download SBOMs (167 repos) - ~2m 40s
Total: ~3m 10s
```

### API Fetcher:
```
Step 1: Fetch root SBOM via API - ~1s
Step 2: Parse SBOM packages - ~1s
Step 3: Map to GitHub via npm/PyPI APIs (230 pkgs) - ~2m 18s
Step 4: Download SBOMs (222 repos) - ~2m 00s
Total: ~4m 20s
```

The extra time is spent in Step 3 (registry API calls), but this yields 54 more SBOMs.

## Recommendations

### ‚úÖ Use API Fetcher As Primary Tool
**Reasons:**
1. **More complete** - Finds 230 packages vs 223
2. **More SBOMs** - Downloads 220 vs 166 (+33%)
3. **More stable** - No HTML parsing fragility
4. **Works for private repos** - Doesn't need web UI
5. **Industry standard** - SPDX format, documented APIs

### üîÑ Migration Path
1. **Phase 1**: Make `github_sbom_api_fetcher.py` the default
2. **Phase 2**: Update README to recommend API fetcher
3. **Phase 3**: Keep HTML scraper for historical reference only
4. **Phase 4**: Add API fetcher to CI/CD pipelines

### üìà Future Improvements
1. **Parallel downloads** - Could speed up SBOM downloads
2. **Cache registry results** - Avoid re-querying npm/PyPI
3. **Support more ecosystems** - Maven, RubyGems, Go modules
4. **Progress bar** - Better UX for long-running operations

## Conclusion

The **API-based fetcher is superior in every meaningful way**:

| Criteria | Winner |
|----------|---------|
| Completeness | ‚úÖ API Fetcher (230 vs 223) |
| SBOM Count | ‚úÖ API Fetcher (220 vs 166) |
| Stability | ‚úÖ API Fetcher (no HTML) |
| Private Repos | ‚úÖ API Fetcher (works) |
| Speed | ‚ö†Ô∏è HTML Scraper (3m vs 4m) |

**4 out of 5 criteria favor the API fetcher**, with the speed difference being minimal (1m 10s) for 54 additional SBOMs.

## Next Steps

1. ‚úÖ **Adopt API fetcher as primary tool**
2. Update documentation and README
3. Add comprehensive tests
4. Consider deprecating HTML scraper
5. Optimize registry API calls (caching, parallel)
6. Add support for more package ecosystems

---

**Generated:** 2025-11-24  
**Test Repo:** tedg-dev/beatBot  
**Tools Compared:** github_sbom_scraper.py vs github_sbom_api_fetcher.py
